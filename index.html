<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications_chronological.html">Research&nbsp;(by&nbsp;year)</a></div>
<div class="menu-item"><a href="publications.html">Research&nbsp;(by&nbsp;topic)</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="documents/resume/Raaz_CV.pdf">CV</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h1>Raaz RSK Dwivedi</h1>
<table class="imgtable"><tr><td>
<img src="images/fly.jpg" alt="Coming soon!" width="292px" height="235px" />&nbsp;</td>
<td align="left"><p><a href="https://fodsi.us/">FODSI Postdoctoral Fellow</a>
<br /> <a href="https://www.seas.harvard.edu/">Harvard University</a> <br />
<a href="https://web.mit.edu/">Massachusetts
Institute of Technology</a> <br /></p>
<p>Harvard contact: <a href="mailto:raaz@seas.harvard.edu">raaz@seas.harvard.edu</a>, 2.339, <a href="https://goo.gl/maps/f5vdxfNGX8vaUbjW7">SEC Harvard
SEAS</a>
<br />
MIT contact:  <a href="mailto:raaz@mit.edu">raaz@mit.edu</a>, 32-566, <a href="https://goo.gl/maps/FK7Z2oFVh9oPt1dE9">Stata Center</a>
<br /></p>
<p><a href="https://goo.gl/T21Lwz">Google Scholar</a>, 
<a href="https://www.semanticscholar.org/author/Raaz-Dwivedi/35688808">Semantic Scholar</a>,
<a href="http://dblp.uni-trier.de/pers/hd/d/Dwivedi:Raaz">DBLP Profile</a><br /></p>
</td></tr></table>
<h2>Short Bio</h2>
<ul>
<li><p><i>Research interests:</i> High dimensional statistics, MCMC methods, and more recently causal inference</p>
</li>
<li><p><i>2021-current:</i> FODSI Postdoctoral Fellow, <a href="https://www.seas.harvard.edu/">Harvard</a> &amp; <a href="https://web.mit.edu/">MIT</a> joint with <a href="http://people.seas.harvard.edu/~samurphy/">Prof. Susan Murphy</a> and <a href="https://devavrat.mit.edu/">Prof. Devavrat Shah</a></p>
</li>
<li><p><i>2015-2021:</i> Ph.D., EECS, <a href="http://www.berkeley.edu">University of California, Berkeley</a>, advised jointly by <a href="https://people.eecs.berkeley.edu/~wainwrig/">Prof. Martin
Wainwright</a> and 
<a href="https://www.stat.berkeley.edu/~yugroup/Bin.html">Prof. Bin Yu</a> (<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-180.html">thesis</a>)</p>
</li>
<li><p><i>Summer 2019:</i> Research internship,
<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/">Microsoft Research New
England</a>, hosted by <a href="http://stanford.edu/~lmackey/">Lester Mackey</a></p>
</li>
<li><p><i>2014-2015:</i> Senior Quantitative Researcher, <a href="http://www.worldquant.com/locations/mumbai/">WorldQuant Research Mumbai</a></p>
</li>
<li><p><i>Summer 2013:</i> Research internship,
<a href="https://ee.stanford.edu/">EE</a>, <a href="https://www.stanford.edu/">Stanford University</a>, hosted by <a href="https://web.stanford.edu/~balaji/">Prof. Balaji Prabhakar</a></p>
</li>
<li><p><i>2010-2014:</i> B.
Tech., <a href="https://www.ee.iitb.ac.in/">EE</a>, <a href="http://www.iitb.ac.in">IIT Bombay</a> with undergrad adviser <a href="https://www.ee.iitb.ac.in/web/faculty/homepage/borkar">Prof. Vivek Borkar</a> (<a href="documents/slides_poster/btp_thesis.pdf">thesis</a>)</p>
</li>
</ul>
<h2>News</h2>
<ul>
<li><p><i>Mar 2022</i>: <b><a href="https://imstat.org/ims-awards/ims-new-researcher-travel-award/">IMS New Researchers Travel Award</a></b> for the <a href="https://www.imsannualmeeting-london2022.com/">IMS Annual Meeting</a> 2022, London!</p>
</li>
<li><p><i>Feb 2022</i>: Joint work with Susan Murphy and Devavrat Shah on &lsquo;&lsquo;<a href="https://arxiv.org/abs/2202.06891">Counterfactual inference in sequential experimental design</a>&rsquo;&rsquo; up on arxiv; also presented at the <a href="https://simons.berkeley.edu/talks/counterfactual-inference-sequential-experiment-design">Simons workshop on Learning from Interventions</a> (<a href="https://www.youtube.com/watch?v=X5bhzwtPLM8">video</a>)</p>
</li>
<li><p><i>Jan 2022</i>: <b><a href="https://lidsconf.mit.edu/2022/index.html">Best Presentation Award</a></b> for the talk on &lsquo;&lsquo;<a href="documents/slides_poster/gkt_compress_slides.pdf">Near-optimal Compression in Near-linear Time</a>&rsquo;&rsquo;  at <a href="https://lidsconf.mit.edu/2022/index.html">27th Annual LIDS Student Conference</a>, Machine Learning and Statistics Session at MIT</p>
</li>
<li><p><i>Jan 2022</i>: <b><a href="https://community.amstat.org/jointscsg-section/awards/student-paper-competition">Best Student Paper Award</a></b> to joint work &lsquo;&lsquo;<a href="https://arxiv.org/abs/2111.07941">Distribution compression in near-linear time</a>&rsquo;&rsquo; with Abhishek Shetty and Lester Mackey in <a href="https://community.amstat.org/jointscsg-section/awards/student-paper-competition">Sections on Statistical Computing and Statistical Graphics</a> by <a href="https://www.amstat.org/">American Statistical Association (ASA)</a>; also accepted for presentation at <a href="https://iclr.cc/">ICLR 2022</a> and <a href="http://approximateinference.org/">AABI 2022</a></p>
</li>
<li><p><i>Jan 2022</i>: Joint work with Lester Mackey &lsquo;&lsquo;<a href="https://arxiv.org/abs/2110.01593">Generalized kernel thinning</a>&rsquo;&rsquo; accepted for presentation at <a href="https://iclr.cc/">ICLR 2022</a> and <a href="http://approximateinference.org/">AABI 2022</a></p>
</li>
<li><p><i>Jan 2022</i>: Excited to be a teaching fellow along with Eura Zhang in <a href="http://people.seas.harvard.edu/~samurphy/teaching/stat234spring2022/syllabus.htm">Stat 234: Sequential Decision Making</a> by Susan Murphy</p>
</li>
<li><p><i>Nov 2021</i>: Github repo &lsquo;&lsquo;<b><a href="https://github.com/microsoft/goodpoints">GoodPoints</a></b>&rsquo;&rsquo; containing python package for new practical and provable algorithms&#8201;&mdash;&#8201;<a href="https://arxiv.org/abs/2105.05842">Kernel thinning</a> and <a href="https://arxiv.org/abs/2111.07941">Compress++</a>&#8201;&mdash;&#8201;for generating concise, high-quality summaries of a probability distribution goes live! </p>
</li>
<li><p><b>Upcoming Presentations!!</b></p>
<ul>
<li><p><i>Apr 2022</i>: <a href="https://iclr.cc/Conferences/2022">International Conference on Learning Theory</a> (ICLR) 2022 (on zoom)!</p>
</li>
<li><p><i>Apr 2022</i>: <a href="https://meetings.siam.org/program.cfm?CONFCODE=uq22">SIAM Conference on Uncertainty Quantification</a> in the mini-symposium on <a href="https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=73573">Kernel methods for numerical integration</a> in Atlanta!</p>
</li>
<li><p><i>June 2022</i>: <a href="https://www.imsannualmeeting-london2022.com/">IMS Annual Meeting</a> in <a href="https://www.imsannualmeeting-london2022.com/invited-sessions">the Statistical Machine Learning session</a> in London!</p>
</li>
<li><p><i>July 2022</i>: <a href="https://sites.google.com/site/boumedienehamzi/symposium-on-algorithmic-information-theory-and-machine-learning">Symposium on Algorithmic Information Theory &amp; Machine Learning</a> at the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a> in London!</p>
</li>
<li><p><i>Aug 2022</i>: <a href="https://ww2.amstat.org/meetings/jsm/2022/onlineprogram/AbstractDetails.cfm?abstractid=322588">Joint Statistical Meeting</a> (JSM) in Washington DC!</p>
</li>
</ul>

</li>
</ul>
<h2>Recent talks</h2>
<ul>
<li><p><b> Counterfactual Inference in Sequential Experimental Design&#8201;&mdash;&#8201;<a href="https://www.youtube.com/watch?v=X5bhzwtPLM8">video</a> | <a href="documents/slides_poster/counterfactual_slides.pdf">slides</a> | <a href="documents/slides_poster/counterfactual_poster.pdf">poster</a> | <a href="https://arxiv.org/abs/2202.06891">preprint</a></b> </p>
<ul>
<li><p><i><a href="https://sdscon.mit.edu/">MIT Statistics and Data Science Conference (SDSCon)</a></i>: Talk and poster, April 2022</p>
</li>
<li><p><i><a href="https://economics.mit.edu/">MIT, Department of Economics</a></i>: Econometrics Lunch, Mar 2022</p>
</li>
<li><p><i><a href="https://www.eecs.mit.edu/eecs-events/lids-stats-tea-talk-raaz-dwivedi-lids-and-harvard/">MIT, LIDS, Department of EECS</a></i>: LIDS &amp; Stats Tea Talk, Mar 2022</p>
</li>
<li><p><i><a href="https://simons.berkeley.edu/programs/Causality2022">Simons Institute, Berkeley</a></i>: Invited talk in the workshop on <a href="https://simons.berkeley.edu/workshops/causality-workshop1">Learning from interventions</a>, Feb 2022</p>
</li>
<li><p><i><a href="https://statistics.fas.harvard.edu/">Harvard University, Department of Statistics</a></i>: Talk at <a href="https://statistics.fas.harvard.edu/stat-300">Stat 300</a>, Feb 2022</p>
</li>
<li><p><i><a href="https://fodsi.us/">FODSI Meetings</a></i>: Invited talks at <a href="https://simons.berkeley.edu/workshops/schedule/18913">FODSI Retreat</a>, Jan 2022, and Advisory Board Meeting Feb 2022</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b> Near-optimal Compression in Near-linear Time&#8201;&mdash;&#8201;<a href="https://www.msri.org/workshops/1020/schedules/31041">video</a> | <a href="documents/slides_poster/near_optimal_slides.pdf">slides</a> | <a href="https://arxiv.org/abs/2110.01593">COLT paper</a> | <a href="https://arxiv.org/abs/2111.07941">ICLR paper</a> | <a href="https://github.com/microsoft/goodpoints">code</a></b></p>
<ul>
<li><p><i><a href="https://www.msri.org/workshops/1020">Mathematical Sciences Research Institute (MSRI), Berkeley</a></i>: Invited talk in the workshop on <a href="https://www.msri.org/workshops/1020">Foundations of Stable, Generalizable and Transferable Statistical Learning</a>, Mar 2022</p>
</li>
<li><p><i><a href="https://lidsconf.mit.edu/2022/index.html">LIDS Student Conference, MIT</a></i>: Contributed talk in Machine Learning and Statistics Session, Jan 2022</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b> Kernel Thinning&#8201;&mdash;&#8201;<a href="http://www.learningtheory.org/colt2021/virtual/poster_1266.html">video</a> | <a href="documents/slides_poster/kt_slides.pdf">slides</a> | <a href="documents/slides_poster/kt_poster.pdf">poster</a> | <a href="https://arxiv.org/abs/2105.05842">COLT paper</a> | <a href="https://arxiv.org/abs/2110.01593,">ICLR paper</a> | <a href="https://github.com/microsoft/goodpoints">code</a> </b> </p>
<ul>
<li><p><i>Harvard University</i>: Invited talk at Finale Doshi-Velez's Data to Actionable Knowledge Lab (<a href="https://dtak.github.io/">DTAK</a>), Oct 2021</p>
</li>
<li><p><i>Alan Turing Institute</i>: Invited talk at the Data-Centric Engineering Reading Group (<a href="https://sites.google.com/view/dce-reading-group">DCE</a>), Sep 2021</p>
</li>
<li><p><i>Monte Carlo Methods and Applications</i> (<a href="https://www.uni-mannheim.de/mcm-2021/">MCM</a>): Contributed talk, Sep, 2021</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b> Revisiting Minimum Description Length Complexity in Overparameterized Models&#8201;&mdash;&#8201;<a href="https://www.youtube.com/watch?v=P4S-JQ_fSdo">video</a> | <a href="documents/slides_poster/mdl_slides.pdf">slides</a> | <a href="documents/slides_poster/mdl_poster.pdf">poster</a> | <a href="https://arxiv.org/abs/2006.10189">preprint</a> </b> </p>
<ul>
<li><p><i>Collaborations on the Theoretical Foundations of Deep Learning</i> <a href="https://deepfoundations.ai/">deepfoundations.ai</a>: Invited talk, Nov 2021</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b> Other talks </b> </p>
<ul>
<li><p>Non-asymptotic Guarantees for High-Dimensional Sampling&#8201;&mdash;&#8201;<a href="documents/slides_poster/mcmc_slides.pdf">slides</a> | <a href="http://jmlr.org/papers/v20/19-306.html">JMLR paper (MALA)</a> | <a href="https://jmlr.org/papers/v21/19-441.html">JMLR paper (HMC)</a> | <a href="https://jmlr.org/papers/v19/18-158.html">JMLR paper (Vaidya/John walks)</a></p>
</li>
<li><p>Stable Discovery of Interpretable Subgroups in Causal Studies&#8201;&mdash;&#8201;<a href="documents/slides_poster/stadisc_slides.pdf">slides</a> | <a href="documents/slides_poster/stadisc_poster.pdf">poster</a> | <a href="https://arxiv.org/abs/2008.10109">Int. Stat. Review paper</a></p>
</li>
</ul>

</li>
</ul>
<h2>Detailed Bio </h2>
<p>(Also see <a href="documents/bio.txt">here</a> for a bio in third person.)</p>
<p><b>Postdoc and Ph.D.</b>: I am currently a <a href="https://fodsi.us/index.html">FODSI</a> postdoc fellow and fortunate to be advised by <a href="http://people.seas.harvard.edu/~samurphy/">Prof. Susan Murphy</a> in the Departments
of <a href="https://www.seas.harvard.edu/computer-science">Computer Science</a> and <a href="https://statistics.fas.harvard.edu/">Statistics</a> at 
<a href="https://www.seas.harvard.edu/">Harvard</a>, and <a href="https://devavrat.mit.edu/">Prof. Devavrat Shah</a> in the Laboratory of
Information Decision and Systems (<a href="https://lids.mit.edu/">LIDS</a>), <a href="https://www.eecs.mit.edu/">Department of
EECS</a> at <a href="https://web.mit.edu/">MIT</a>. I finished my Ph.D. in Summer 2021 from the <a href="http://www.eecs.berkeley.edu/">Department
of EECS</a> at the <a href="http://www.berkeley.edu">UC Berkeley</a> where I was fortunate to be advised by <a href="https://people.eecs.berkeley.edu/~wainwrig/">Prof. Martin
Wainwright</a> and  <a href="https://www.stat.berkeley.edu/~yugroup/Bin.html">Prof. Bin Yu</a>. 
My thesis committee members included <a href="https://www.stat.berkeley.edu/~aldous/">Prof. David Aldous</a> and <a href="https://www.stat.berkeley.edu/~bartlett/">Prof. Peter Bartlett</a>. I was also fortunate to work with several collaborators, including <a href="https://people.eecs.berkeley.edu/~jordan/">Prof. Michael Jordan</a> at UC Berkeley, <a href="http://stanford.edu/~lmackey/">Lester Mackey</a> at  <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/">Microsoft Research</a> (MSR), and <a href="https://provost.northeastern.edu/leadership/david-madigan/">Prof. David Madigan</a> at the <a href="https://www.northeastern.edu/">Northeastern University</a> (formerly at <a href="https://www.columbia.edu/">Columbia University</a>). At Berkeley, I was associated with the  Berkeley Laboratory for Information and System Sciences (<a href="https://bliss.eecs.berkeley.edu/,">BLISS</a>), and the Berkeley Artificial Intelligence Research group (<a href="http://bair.berkeley.edu/">BAIR</a>). </p>
<p><b>Research interests</b>: My research interests include both the theoretical and applied aspects of statistical machine learning and data science. My recent works cover various topics in high-dimensional statistics with a focus on random sampling, improving sample quality. More recently, I have started thinking about problems at the intersection of reinforcement learning and causal inference.</p>
<p><b>Awards</b>: My work on <a href="https://arxiv.org/abs/2111.07941">distribution compression</a> won the best student paper award in <a href="https://community.amstat.org/jointscsg-section/awards/student-paper-competition">ASA sections on statistical computing and statistical graphics</a>. At UC Berkeley, I was awarded the  <a href="https://gsi.berkeley.edu/programs-services/award-programs/ogsi/ogsi-2020/">Outstanding Graduate Student Instructor Award</a> in 2020.  I also received the prestigious  <a href="http://grad.berkeley.edu/admissions/apply/fellowships-entering/">Berkeley Fellowship</a>, the highest award for the incoming graduate students, in 2015. During my graduation at IIT Bombay, I was awarded the  <a href="https://www.iitbombay.org/iitb_dean_acr/september-2014-newsletter/52nd%20Convocation%20of%20IIT%20Bombay.pdf">President of India Gold Medal</a>, the highest honor to a graduating batch of students, the <a href="http://www.cdeep.iitb.ac.in/convocation/Convocation_Brochure_2015.pdf">Institute Silver Medal</a> for the highest GPA, and the Best B. Tech Project Award in the EE department.</p>
<p><b>Work experience:</b> 
I spent the summer of 2019 as
a research intern at 
<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/">Microsoft Research New
England</a>.
I also spent the summer of 2017 as an intern at
<a href="https://www.mist.com/">Mist systems, Cupertino</a> (later acquired by 
<a href="https://www.juniper.net/us/en/">Juniper Networks</a>).
Before joining UC Berkeley, I worked for a year at <a href="http://www.worldquant.com/locations/mumbai/">WorldQuant Research</a> in <a href="https://en.wikipedia.org/wiki/Mumbai/">Mumbai, India</a>, as a Senior
Quantitative Researcher.
During my undergrad, I spent the summer of 2013 at <a href="https://www.stanford.edu/">Stanford University</a>
as an intern with <a href="https://web.stanford.edu/~balaji/">Prof. Balaji Prabhakar</a>, and the winter of 2012
at <a href="https://ivymobility.com/">Ivy Mobility</a>.</p>
<p><b>Pre-Ph.D. life</b>: Before UC Berkeley, I graduated from the <a href="http://www.iitb.ac.in">Indian
Institute of Technology, Bombay</a> (IIT Bombay), with a B.
Tech. (Honors) in <a href="http://www.ee.iitb.ac.in">Electrical Engineering</a> and Minors in 
<a href="http://www.math.iitb.ac.in">Mathematics</a>. At IIT Bombay, I was also fortunate to work with 
<a href="https://www.ee.iitb.ac.in/web/faculty/homepage/borkar">Prof. Vivek Borkar</a>, 
<a href="https://www.ee.iitb.ac.in/wiki/faculty/prnair">Prof. Pradeep Nair</a>,
and  <a href="https://www.ee.iitb.ac.in/wiki/faculty/vasi">Prof. Juzer Vasi</a>.</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-04-03 13:38:56 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
